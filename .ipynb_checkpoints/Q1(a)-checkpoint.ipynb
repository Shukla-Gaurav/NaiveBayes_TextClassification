{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import utils as utility\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def get_modal(docs,stemming):\n",
    "    stars = np.zeros(5)\n",
    "    category_count = np.zeros(5)\n",
    "\n",
    "    class_frequency = {}\n",
    "    count = 0\n",
    "    all_words = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        count = count + 1\n",
    "        if(stemming):\n",
    "            words = utility.getStemmedDocuments(doc['text'])\n",
    "        else:\n",
    "            words = doc['text'].split()\n",
    "\n",
    "        star = int(doc['stars'])\n",
    "        stars[star-1] += 1\n",
    "        category_count[star-1] += len(words)\n",
    "\n",
    "        for word in words:\n",
    "            if word not in class_frequency:\n",
    "                all_words.append(word)\n",
    "                class_frequency[word] = np.ones(5)\n",
    "            class_frequency[word][star-1] += 1\n",
    "\n",
    "    #print(class_frequency)\n",
    "    #print(all_words)\n",
    "\n",
    "    m = count\n",
    "    vocab_size = len(all_words)\n",
    "    category_count += vocab_size\n",
    "\n",
    "    for i in all_words:\n",
    "        class_frequency[i] = np.log(class_frequency[i]/category_count)\n",
    "    #parameter_matrix = np.log(np.array(frequency_matrix)/category_count)\n",
    "\n",
    "    phai_y = np.log(stars/m)\n",
    " \n",
    "    parameters = [class_frequency,phai_y,category_count]\n",
    "    #write the object into the file\n",
    "    if(stemming):\n",
    "        file_name = \"probability_stemming\"\n",
    "    else:\n",
    "        file_name = \"probability_withoutstemming\"\n",
    "    # open the file for writing\n",
    "    obj_writer = open(file_name,'wb') \n",
    "    \n",
    "    pickle.dump(parameters,obj_writer)   \n",
    "    obj_writer.close()\n",
    "    print('done')\n",
    "    return \n",
    "\n",
    "docs =  utility.json_reader('../train.json')\n",
    "get_modal(docs,False)\n",
    "#get_modal(docs,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.91963004 -3.90369144 -3.74918142 -3.65761656 -3.77639682]\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "(0.6187050359712231, array([[15493,  2174,  1124,   873,   505],\n",
      "       [ 3377,  1962,  2935,  2086,   478],\n",
      "       [ 1615,   819,  3646,  7302,  1149],\n",
      "       [ 1067,   266,  1137, 18545,  8343],\n",
      "       [ 2479,   107,   253, 12897, 43086]]))\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pickle\n",
    "import utils as utility\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "\n",
    "def get_the_object(file_name):\n",
    "    # we open the file for reading\n",
    "    obj_reader = open(file_name,'rb')  \n",
    "    parameters = pickle.load(obj_reader)  \n",
    "    obj_reader.close()\n",
    "    #print(parameters[1])\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def get_predicted_class(stemming,parameters):\n",
    "    count = 0 \n",
    "    correct_prediction = 0\n",
    "    prob_dict = parameters[0]\n",
    "    print(prob_dict['a'])\n",
    "    phai_y=parameters[1]\n",
    "    category_count = parameters[2]\n",
    "    docs =  utility.json_reader('../test.json')\n",
    "    prediction =[]\n",
    "    original = []\n",
    "    for doc in docs:\n",
    "        if(count%1000 == 0):\n",
    "            print(count)\n",
    "        count += 1\n",
    "        review = doc['text']\n",
    "        \n",
    "        if(stemming):\n",
    "            words = utility.getStemmedDocuments(review)\n",
    "        else:\n",
    "            words = review.split()\n",
    "\n",
    "        sum_of_logs = phai_y\n",
    "        for word in words:\n",
    "            if word not in prob_dict:\n",
    "                sum_of_logs = np.add(sum_of_logs,np.log(1/category_count))\n",
    "            else:\n",
    "                sum_of_logs = np.add(sum_of_logs,prob_dict[word])\n",
    "\n",
    "#         max_value = sum_of_logs[0]\n",
    "#         max_ind = 0\n",
    "#         for i in range(1,5):\n",
    "#             if(sum_of_logs[i] > max_value):\n",
    "#                 max_value = sum_of_logs[0]\n",
    "#                 max_ind = i\n",
    "#         prediction = max_ind+1\n",
    "\n",
    "        prediction.append(np.argmax(sum_of_logs)+1)\n",
    "        original.append(int(doc['stars']))\n",
    "       \n",
    "    return prediction,original\n",
    "\n",
    "def compute_testdata_accuracy_stemming():\n",
    "    docs =  utility.json_reader('../test.json')\n",
    "    count = 0\n",
    "    \n",
    "    parameters = get_the_object(\"probability_stemming\")\n",
    "    for doc in docs:\n",
    "        count += 1\n",
    "        prediction = get_predicted_class(doc['text'],True,parameters)\n",
    "        star = int(doc['stars'])\n",
    "        \n",
    "        if(star == prediction):\n",
    "            correct_prediction += 1\n",
    "    return correct_prediction/count\n",
    "\n",
    "def compute_testdata_accuracy():\n",
    "    \n",
    "    parameters = get_the_object(\"probability_withoutstemming\")\n",
    "    prediction,original = get_predicted_class(False,parameters)\n",
    "    return accuracy_score(original,prediction),confusion_matrix(original,prediction)\n",
    "    \n",
    "print(compute_testdata_accuracy())\n",
    "#print(compute_testdata_accuracy_stemming())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
